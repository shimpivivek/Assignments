{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f33ada-2da7-40cc-87be-e66431b31136",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11618fc-24fe-44b6-b0a4-54f9f16324c6",
   "metadata": {},
   "source": [
    "Missing values in a dataset refer to the absence of information or data for certain observations or features. They can occur due to various reasons, such as data collection errors, sensor malfunctions, or simply because the information was not available.\n",
    "\n",
    "#### It is essential to handle missing values for several reasons:\n",
    "\n",
    "Prevent Biased Analysis: Missing values can lead to biased or incorrect analyses and predictions.\n",
    "\n",
    "Maintain Data Integrity: Including missing values can cause issues in computations and visualizations.\n",
    "\n",
    "Improve Model Performance: Most machine learning algorithms do not handle missing values well, and their presence can lead to incorrect predictions or biased models.\n",
    "\n",
    "\n",
    "#### Algorithms that are not affected by missing values include:\n",
    "\n",
    "Decision Trees: They can handle missing values during the splitting process by considering alternative branches for instances with missing data.\n",
    "\n",
    "Random Forests: Like decision trees, random forests can handle missing values effectively due to their ensemble nature.\n",
    "\n",
    "K-Nearest Neighbors (KNN): KNN can work with missing values by using a distance metric that ignores missing values when calculating similarities.\n",
    "\n",
    "Naive Bayes: It can handle missing values because it estimates class probabilities independently for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf6086c-d79d-4e34-9e04-1724c2eb3a30",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1071fb38-f9d4-4192-b108-df62910fd3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "1  2.0  2.0\n",
      "4  5.0  5.0\n"
     ]
    }
   ],
   "source": [
    "\"1) Deletion of Missing Data:\"\n",
    "import pandas as pd\n",
    "data = {'A': [1, 2, None, 4, 5], 'B': [None, 2, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f87b584-5faa-48e4-a040-2580f3bbafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A         B\n",
      "0  1.0  4.666667\n",
      "1  2.0  5.000000\n",
      "2  3.0  4.000000\n",
      "3  4.0  4.666667\n",
      "4  5.0  5.000000\n"
     ]
    }
   ],
   "source": [
    "\"2) Mean Imputation\"\n",
    "data = {'A': [1, 2, None, 4, 5], 'B': [None, 5, 4, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "df_imputed = df.fillna(df.mean())\n",
    "\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88557d7e-de3d-4f9c-8bdb-64d256c327c2",
   "metadata": {},
   "source": [
    "3) Using Domain Knowledge:\n",
    "\n",
    "This involves manually filling missing values based on subject matter expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4499963-83f0-456b-9cc5-c4924f5e0c71",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52665e7d-3cb2-4395-89ad-9510e84f6915",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation in a classification problem where the classes are not represented equally. One class has significantly fewer instances than the other.\n",
    "\n",
    "If imbalanced data is not handled, several issues may arise:\n",
    "\n",
    "Biased Model: The model tends to be biased towards the majority class. It may become overly specialized in predicting the majority class, leading to poor performance on the minority class.\n",
    "\n",
    "Misleading Accuracy: The model's accuracy can be misleadingly high. For instance, if 95% of the data belongs to the majority class, a model that predicts the majority class for every instance would still achieve 95% accuracy.\n",
    "\n",
    "Failure to Identify Rare Events: In scenarios where the minority class represents an important outcome (e.g., fraud detection, rare diseases), the model may fail to identify critical instances.\n",
    "\n",
    "Loss of Information: The valuable information from the minority class might be overlooked or ignored, leading to incomplete and potentially biased insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906b8795-8179-4d3d-b7c2-7f4a1fc90ff5",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2283b-f7cc-445d-aff6-581c39cfc073",
   "metadata": {},
   "source": [
    "### Up-sampling:\n",
    "\n",
    "Up-sampling involves increasing the number of instances in the minority class to balance it with the majority class. This can be done by duplicating existing instances or generating synthetic data points.\n",
    "\n",
    "### Down-sampling:\n",
    "\n",
    "Down-sampling involves reducing the number of instances in the majority class to balance it with the minority class. This can be achieved by randomly removing instances or using more advanced techniques.\n",
    "\n",
    "When to Use Up-sampling and Down-sampling:\n",
    "\n",
    "Up-sampling is typically used when the minority class is under-represented and generating synthetic examples or duplicating existing ones can help the model learn more about the minority class.\n",
    "\n",
    "Down-sampling is employed when the majority class is excessively represented, potentially causing the model to be biased towards it. By reducing the number of instances in the majority class, we can create a more balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779db64f-a89f-4c3b-99a1-9a276823502f",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444c178-f8c7-420e-a2eb-3cd2fa2650d9",
   "metadata": {},
   "source": [
    "Data Augmentation is a technique used to artificially increase the size of a dataset by applying various transformations to the existing data. This is commonly used in computer vision and natural language processing tasks.\n",
    "\n",
    "### SMOTE (Synthetic Minority Over-sampling Technique):\n",
    "\n",
    "SMOTE is a technique used to address class imbalance in classification tasks. It focuses on the minority class by generating synthetic samples that are similar to existing instances. Here's how it works:\n",
    "\n",
    "Select a Minority Instance: Randomly choose a sample from the minority class.\n",
    "\n",
    "Find Nearest Neighbors: Identify its k-nearest neighbors in feature space.\n",
    "\n",
    "Create Synthetic Instances: Randomly select one of the neighbors and generate a random linear combination of the feature values between the chosen neighbor and the original instance. This creates a new synthetic sample.\n",
    "\n",
    "Repeat: Repeat steps 1-3 to create as many synthetic samples as needed to balance the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f53f7-c86d-46f0-99e6-dc6680d0cc1c",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c126b-51c1-4d35-8da4-09ce03ad11cd",
   "metadata": {},
   "source": [
    "Outliers in a dataset are data points that significantly deviate from the rest of the observations. They can be unusually high or low values that do not follow the general trend or distribution of the data.\n",
    "\n",
    "It is essential to handle outliers for several reasons:\n",
    "\n",
    "Impact on Statistical Measures: Outliers can skew statistical measures like mean and standard deviation, leading to inaccurate summaries of the data.\n",
    "\n",
    "Influence on Model Performance: Outliers can have a significant impact on the performance of machine learning models, particularly those sensitive to extreme values, like linear regression.\n",
    "\n",
    "Misleading Interpretations: Outliers can mislead data analysts and researchers about the underlying patterns and trends in the data.\n",
    "\n",
    "Robustness of Models: Handling outliers improves the robustness and reliability of models, ensuring they perform well on real-world data.\n",
    "\n",
    "Improving Data Quality: Removing or appropriately transforming outliers helps in maintaining data quality and integrity.\n",
    "\n",
    "Preserving Assumptions: Some statistical techniques and models assume that the data follows a certain distribution. Outliers can violate these assumptions, leading to incorrect conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016d263-8751-494c-9978-7e1bfd2a0431",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ead29f-9e91-4a1b-9294-4dab2d7c4949",
   "metadata": {},
   "source": [
    "Imputation: Use methods like mean, median, or mode imputation to fill in missing values based on the characteristics of the dataset.\n",
    "\n",
    "Predictive Model Imputation: Employ algorithms to predict missing values based on the relationships between variables.\n",
    "\n",
    "Domain Knowledge: Leverage subject matter expertise to estimate or derive missing values, especially if certain features are correlated.\n",
    "\n",
    "Deletion: If feasible, remove rows or columns with significant missing data, ensuring it won't compromise the analysis.\n",
    "\n",
    "Multiple Imputation: Generate multiple imputed datasets to account for uncertainty in the imputation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed95277-9e9d-4887-ba03-74ca06fe792f",
   "metadata": {},
   "source": [
    "## Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd7e53-4ca5-4d48-b2ad-3ea01bb0de78",
   "metadata": {},
   "source": [
    "Visual Inspection:\n",
    "\n",
    "Create plots like heatmaps or missing value matrices to visually examine the pattern of missingness across variables.\n",
    "\n",
    "Correlation Analysis:\n",
    "\n",
    "Check if there are correlations between missing values in different variables. This may indicate a pattern.\n",
    "\n",
    "Statistical Tests:\n",
    "\n",
    "Perform hypothesis tests to assess if the missingness is related to certain characteristics or variables in the dataset.\n",
    "\n",
    "Imputation Impact:\n",
    "\n",
    "Impute missing values using different methods and compare results. If imputation methods significantly affect results, it may indicate non-random missingness.\n",
    "\n",
    "Domain Knowledge:\n",
    "\n",
    "Utilize subject matter expertise to understand if there are plausible reasons for specific data points being missing.\n",
    "\n",
    "Missing Data Mechanism Tests\n",
    "\n",
    "Employ statistical tests (e.g., Little's MCAR test, MAR test) to formally assess the missing data mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ffbcb-1bac-40e0-977b-decaf9e25f7e",
   "metadata": {},
   "source": [
    "## Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f7c6d-27ec-436d-a81e-18b59744b41c",
   "metadata": {},
   "source": [
    "### Resampling Techniques:\n",
    "\n",
    "Employ methods like up-sampling the minority class, down-sampling the majority class, or using techniques like Synthetic Minority Over-sampling Technique (SMOTE) to balance the classes.\n",
    "\n",
    "### Ensemble Methods:\n",
    "\n",
    "Utilize ensemble techniques like Random Forest or Gradient Boosting, which are robust to class imbalances.\n",
    "\n",
    "### Cost-Sensitive Learning:\n",
    "\n",
    "Adjust the class weights during model training to penalize misclassifying the minority class more than the majority class.\n",
    "\n",
    "### Anomaly Detection:\n",
    "\n",
    "Treat the problem as an anomaly detection task, where the rare class is treated as the \"anomaly\" and models are trained to detect it.\n",
    "\n",
    "### Collect More Data:\n",
    "\n",
    "If possible, collect additional data, especially from the minority class, to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b282fc-9db4-45a8-9937-39872275388a",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f8676-6bf2-4782-a7e4-7e2cfcaf8378",
   "metadata": {},
   "source": [
    "### Random Under-sampling:\n",
    "\n",
    "Randomly remove instances from the majority class to match the size of the minority class. This can be effective if the dataset is large enough.\n",
    "\n",
    "### Cluster-Based Under-sampling:\n",
    "\n",
    "Apply clustering techniques to group similar instances, then randomly select representatives from each cluster.\n",
    "\n",
    "### Edited Nearest Neighbors:\n",
    "\n",
    "Identify and remove instances whose class differs from the majority of their k-nearest neighbors.\n",
    "\n",
    "### Combining Techniques:\n",
    "\n",
    "Utilize a combination of over-sampling the minority class and under-sampling the majority class to achieve a balanced dataset.\n",
    "\n",
    "### Synthetic Minority Over-sampling Technique (SMOTE):\n",
    "\n",
    "Although typically used for over-sampling, SMOTE can be applied in conjunction with under-sampling methods for a more balanced dataset.\n",
    "\n",
    "### Ensemble Techniques:\n",
    "\n",
    "Utilize ensemble methods like EasyEnsemble or BalancedRandomForest, which are designed to handle imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452e321-8cc0-4407-977f-c2d995b06395",
   "metadata": {},
   "source": [
    "## Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1425e5-da32-470e-8208-2d77ed11ef9e",
   "metadata": {},
   "source": [
    "### Random Over-sampling:\n",
    "\n",
    "Duplicate random instances from the minority class to increase its representation in the dataset.\n",
    "\n",
    "### SMOTE (Synthetic Minority Over-sampling Technique):\n",
    "\n",
    "Generate synthetic data points in feature space to create a more balanced dataset.\n",
    "\n",
    "### ADASYN (Adaptive Synthetic Sampling):\n",
    "\n",
    "Similar to SMOTE, but it focuses on generating more samples for the more challenging regions of the minority class.\n",
    "\n",
    "### Borderline-SMOTE:\n",
    "\n",
    "Specifically designed for datasets with noisy and borderline instances. It focuses on generating synthetic samples for these regions.\n",
    "\n",
    "### Ensemble Techniques:\n",
    "\n",
    "Utilize ensemble methods like BalancedRandomForest or EasyEnsemble, which are designed to handle imbalanced datasets.\n",
    "\n",
    "### Cost-Sensitive Learning:\n",
    "\n",
    "Adjust the misclassification costs during model training to penalize errors on the minority class more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0312bc-5818-4d96-87c2-dcf045511734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a4830-121a-4948-8eee-e335c9a51891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ea17c-be5e-45b6-b9c9-0c766751ec76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7f5ff-680d-4815-8398-a49a84dba51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723aa5c-6aae-43b9-bae4-3ffb82ff5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6eea29-8212-4015-93cb-687e2788d891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57b056-cdea-4e30-b4b8-19400721c7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083ec38-fc33-4422-ad03-12bbc515a851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ad865-052b-43dc-ae4c-b6a794e8aa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca52bb4-2cd1-45c9-a1cb-cb6142244a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5e1e1-cbac-4775-bc18-f1c164e8b31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee110db-87d3-4e21-9637-4f81f36304bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3055e7-3a9e-4422-b88e-0ad1d16cd904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a6f16-f0fb-4977-bfee-88d1cdbdb24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc7ba3-2e37-4a73-8de6-df1e6150c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567fef3-b899-423c-be85-a2bccbcd45b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef973132-eca1-40d4-bb3b-4d17926eecf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30cf59-2b11-4174-a812-35d8a08da12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
